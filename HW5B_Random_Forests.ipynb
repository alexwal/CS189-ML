{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alex Walczak | CS 189 | Homework 5 part 2: Decision Trees, Random Forests for Census Data\n",
    "\n",
    "# Import functions and libraries\n",
    "from __future__ import division\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import scipy.io\n",
    "from scipy import signal\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pylab import rcParams\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "rcParams['figure.figsize'] = 7, 7\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Imputing helpers\n",
    "\n",
    "def most_freq_string(array):\n",
    "    unique, all_inds_in_unique_for_items_in_array = np.unique(array,return_inverse=True)\n",
    "    most_freq = unique[np.bincount(all_inds_in_unique_for_items_in_array).argmax()]\n",
    "    return most_freq\n",
    "\n",
    "def get_most_freq_feats(data, missing_value_symbol, categories, categorical_feats):\n",
    "    # Arguments is a data matrix with each row being a sample.\n",
    "    # Takes a majority vote on categorical features and computes mean on numerical features.\n",
    "    clean_feats = np.array([np.array([feat for feat in complete_feat if feat != missing_value_symbol]) for complete_feat in data.T])\n",
    "    res = []\n",
    "    for j in range(len(clean_feats)): # each feature\n",
    "        if categories[j] in categorical_feats:\n",
    "            res += [most_freq_string(clean_feats[j])]\n",
    "        else:\n",
    "            res += [str(np.mean(clean_feats[j].astype(np.float)))]\n",
    "    return np.array(res)\n",
    "\n",
    "def impute_missing_value(data, replace_bad_feats_with, missing_value_symbol):\n",
    "    # Arguments is a data matrix.\n",
    "    for row in data:\n",
    "        row[row == missing_value_symbol] = replace_bad_feats_with[row == missing_value_symbol]\n",
    "        \n",
    "### Evaluating splits\n",
    "        \n",
    "def probability(Y, C, S, distbn=None):\n",
    "# probability of random variable Y being in class C\n",
    "# index set S\n",
    "    count = 0\n",
    "    for i in S:\n",
    "        if Y[int(i)] == C:\n",
    "            count += 1\n",
    "    return count/len(S)\n",
    "\n",
    "def surprise(Y, C, S):\n",
    "# surprise of random variable Y being in class C\n",
    "    return -probability(Y, C, S)*((np.log(probability(Y, C, S)))/np.log(2))\n",
    "\n",
    "def entropy(Y, classes, S):\n",
    "# entropy of an index set S\n",
    "# max = 1 occurs when Y is evenly split [ range = [0,1] ]\n",
    "# (updating of entropy will be optimized, this is a naive version)\n",
    "    H = 0\n",
    "    for C in classes:\n",
    "        H += surprise(Y, C, S)\n",
    "    return H\n",
    "\n",
    "def information_gain(Y, classes, S, Sleft, Sright):\n",
    "    # change in entropy resulting from a split\n",
    "    # we choose the split which maximizes this quanitity\n",
    "    Hafter = (len(Sleft)*entropy(Y, classes, Sleft) + len(Sright)*entropy(Y, classes, Sright))/len(S)\n",
    "    return entropy(Y, classes, S) - Hafter\n",
    "\n",
    "def weighted_sum_of_entropy(Y, classes, S, Sleft, Sright):\n",
    "    # we choose the split which MINimizes this quanitity\n",
    "    Hafter = (len(Sleft)*entropy(Y, classes, Sleft) + len(Sright)*entropy(Y, classes, Sright))/len(S)\n",
    "    return entropy(Y, classes, S) - Hafter\n",
    "\n",
    "def gini_impurity(Y, classes, S):\n",
    "    # Y can be thought of as a vector of labels, where a label equals a class C in classes.\n",
    "    # we are only interested in the labels indexed by S. The other samples aren't being worked on.\n",
    "    sum_prob_squared = 0\n",
    "    for C in classes:\n",
    "        sum_prob_squared+=(probability(Y, C, S)**2)\n",
    "    return 1-sum_prob_squared\n",
    "\n",
    "### Pruning-related\n",
    "\n",
    "def postprune(node, ogtree, tdata, tlabels):\n",
    "    if node == None:\n",
    "        return\n",
    "    if node.label!=None:\n",
    "        return\n",
    "        \n",
    "    postprune(node.left, ogtree, tdata, tlabels)\n",
    "    postprune(node.right, ogtree, tdata, tlabels)\n",
    "    \n",
    "    error_before = np.sum(tlabels != ogtree.predict_all(tdata))/len(tlabels)\n",
    "    testasleaf(node)\n",
    "    error_after = np.sum(tlabels != ogtree.predict_all(tdata))/len(tlabels)\n",
    "\n",
    "    if error_after <= error_before:\n",
    "        converttoleaf(node)\n",
    "    else:\n",
    "        undotestasleaf(node)\n",
    "\n",
    "def testasleaf(node):\n",
    "    # if a node label is not None, the children are never looked at. \n",
    "    # so to prune, we can just set node labels!\n",
    "    if int(np.rint(node.split_rule[1])) >= 1:\n",
    "        node.label = 1\n",
    "    else:\n",
    "        node.label = 0\n",
    "\n",
    "def undotestasleaf(node):\n",
    "    node.label = None\n",
    "    \n",
    "def converttoleaf(node):\n",
    "    node.left = None\n",
    "    node.right = None\n",
    "    node.split_rule = None\n",
    "\n",
    "def countnodesandleaves(node):\n",
    "    if node == None:\n",
    "        return 0\n",
    "    if node.label != None:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 + countnodesandleaves(node.left) + countnodesandleaves(node.right)\n",
    "    \n",
    "### Uncategorized functions\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# Ex. save_labels(spam_labels,'kaggle_spam_mean.csv')\n",
    "def save_labels(labels, fname):\n",
    "    f1 = open(fname, 'w+')\n",
    "    print('Id,Category', file = f1)\n",
    "    for i in range(len(labels)):\n",
    "        print(str(i+1)+\",\"+str(int(labels[i])), file = f1)\n",
    "\n",
    "def generate_inds(data, percent_train, with_replacement=False):\n",
    "    if not with_replacement:\n",
    "        rand_inds = np.random.permutation(len(data))\n",
    "        train_inds = rand_inds[len(data)//percent_train:]\n",
    "        test_inds = rand_inds[:len(data)//percent_train]\n",
    "    else:\n",
    "        train_inds = np.random.choice(len(data), size=len(data), replace=True)\n",
    "        test_inds = np.random.permutation(len(data))[:len(data)//percent_train]\n",
    "    return train_inds, test_inds\n",
    "\n",
    "def avg_prediction(trees, data):\n",
    "    predicted_labels = []\n",
    "    for tree in trees:\n",
    "        predicted_labels += [tree.predict_all(data)]\n",
    "    predicted_labels = np.array([predicted_labels])\n",
    "    return np.rint(np.mean(predicted_labels, axis = 1))\n",
    "\n",
    "def grow_set_trees(num_trees, percent_train, data, labels, treetype='DecisionTree', depth=None, m=None, size_to_stop=None, bagging=False, prune=False):\n",
    "    trees = []\n",
    "    for t in range(num_trees):\n",
    "        print(t+1)\n",
    "        train_inds, unused = generate_inds(data, percent_train, with_replacement=bagging)\n",
    "        training = data[train_inds]\n",
    "        training_labels = labels[train_inds]\n",
    "        \n",
    "        if treetype == 'DecisionTree':\n",
    "            tree = DecisionTree(size_to_stop)\n",
    "        if treetype == 'RandomForest':\n",
    "            tree = RandomForest(size_to_stop, m)\n",
    "  \n",
    "        tree.train(tree.root, data, labels, depth)\n",
    "\n",
    "        if prune:\n",
    "            XXX, prune_inds = generate_inds(data, percent_train)\n",
    "            pruneset = data[prune_inds]\n",
    "            prune_labels = labels[prune_inds]\n",
    "            postprune(tree.root, tree, pruneset, prune_labels)\n",
    "\n",
    "        trees += [tree]\n",
    "    return trees\n",
    "\n",
    "### Cross validation functions\n",
    "\n",
    "def kfold(k, which, data, labels, hyperparam_set, treetype='DecisionTree', depth=None, m=None, size_to_stop=None, bagging=False):\n",
    "    \"\"\"which is one of: 'depth', 'm', 'size_to_stop'.\"\"\"\n",
    "    if which == 'depth':\n",
    "        kfold_depth(k, data, labels, hyperparam_set, treetype, depth, m, size_to_stop, bagging)\n",
    "        return\n",
    "    \n",
    "    if which == 'm':\n",
    "        assert treetype == 'RandomForest'\n",
    "        kfold_m(k, data, labels, hyperparam_set, 'RandomForest', depth, m, size_to_stop, bagging)\n",
    "        return\n",
    "    \n",
    "    if which == 'size_to_stop':\n",
    "        kfold_size_to_stop(k, data, labels, hyperparam_set, treetype, depth, m, size_to_stop, bagging)\n",
    "        return\n",
    "\n",
    "def kfold_m(k, data, labels, ms, treetype='RandomForest', depth=None, m=None, size_to_stop=None, bagging=False):\n",
    "    kf = KFold(data.shape[0], n_folds=k, shuffle = True)\n",
    "    m_errors = np.zeros(len(ms))\n",
    "\n",
    "    for i in range(len(ms)):\n",
    "\n",
    "        print('At m:', ms[i])\n",
    "\n",
    "        for train, test in kf:\n",
    "\n",
    "            ktrain = data[train]\n",
    "            ktrain_label = labels[train]\n",
    "            ktest = data[test]\n",
    "            ktrue = labels[test]\n",
    "\n",
    "            tree = RandomForest(size_to_stop, ms[i])\n",
    "            tree.train(tree.root, ktrain, ktrain_label, depth)\n",
    "\n",
    "            predn_labels = tree.predict_all(ktest);\n",
    "            m_errors[i] += (np.sum(predn_labels != ktrue)/len(ktrue))*(1/k)\n",
    "\n",
    "        print('Error:', m_errors[i])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(ms, m_errors)\n",
    "    plt.title('Result of K-fold CV for m value of '+treetype+', size_to_stop = '+str(size_to_stop)+', depth = '+str(depth))\n",
    "    plt.xlabel('m value')\n",
    "    plt.ylabel('Average Error')\n",
    "    \n",
    "    print('Best m:',ms[m_errors.argmin()])\n",
    "\n",
    "def kfold_depth(k, data, labels, depths, treetype='DecisionTree', depth=None, m=None, size_to_stop=None, bagging=False):\n",
    "    kf = KFold(data.shape[0], n_folds=k, shuffle = True)\n",
    "    depth_errors = np.zeros(len(depths))\n",
    "\n",
    "    for i in range(len(depths)):\n",
    "\n",
    "        print('At depth:', depths[i])\n",
    "\n",
    "        for train, test in kf:\n",
    "\n",
    "            ktrain = data[train]\n",
    "            ktrain_label = labels[train]\n",
    "            ktest = data[test]\n",
    "            ktrue = labels[test]\n",
    "\n",
    "            if treetype == 'DecisionTree':\n",
    "                tree = DecisionTree(size_to_stop)\n",
    "            if treetype == 'RandomForest':\n",
    "                tree = RandomForest(size_to_stop, m)\n",
    "            tree.train(tree.root, ktrain, ktrain_label, depths[i])\n",
    "\n",
    "            predn_labels = tree.predict_all(ktest)\n",
    "            depth_errors[i]+=(np.sum(predn_labels != ktrue)/len(ktrue))*(1/k)\n",
    "\n",
    "        print('Error:', depth_errors[i])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(depths, depth_errors)\n",
    "    plt.title('Result of K-fold CV for Depth of '+treetype+', size_to_stop = '+str(size_to_stop))\n",
    "    plt.xlabel('Depth')\n",
    "    plt.ylabel('Average Error')\n",
    "    \n",
    "    print('Best depth:',depths[depth_errors.argmin()])\n",
    "    \n",
    "def kfold_size_to_stop(k, data, labels, s2s, treetype='DecisionTree', depth=None, m=None, size_to_stop=None, bagging=False):\n",
    "    kf = KFold(data.shape[0], n_folds=k, shuffle = True)\n",
    "    s2s_errors = np.zeros(len(s2s))\n",
    "\n",
    "    for i in range(len(s2s)):\n",
    "\n",
    "        print('At size_to_stop:', s2s[i])\n",
    "\n",
    "        for train, test in kf:\n",
    "\n",
    "            ktrain = data[train]\n",
    "            ktrain_label = labels[train]\n",
    "            ktest = data[test]\n",
    "            ktrue = labels[test]\n",
    "\n",
    "            if treetype == 'DecisionTree':\n",
    "                tree = DecisionTree(s2s[i])\n",
    "            if treetype == 'RandomForest':\n",
    "                tree = RandomForest(s2s[i], m)\n",
    "            tree.train(tree.root, ktrain, ktrain_label, depth)\n",
    "\n",
    "            predn_labels = tree.predict_all(ktest)\n",
    "            s2s_errors[i]+=(np.sum(predn_labels != ktrue)/len(ktrue))*(1/k)\n",
    "\n",
    "        print('Error:', s2s_errors[i])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(s2s, s2s_errors)\n",
    "    plt.title('Result of K-fold CV for size_to_stop of '+treetype+', depth = '+str(depth))\n",
    "    plt.xlabel('Size_to_stop')\n",
    "    plt.ylabel('Average Error')\n",
    "    \n",
    "    print('Best size_to_stop:',s2s[s2s_errors.argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    # for two-class data with binary features vectorized samples.\n",
    "    class Node:\n",
    "        def __init__(self, left=None, right=None, label=None, split_rule=None):\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.label = label\n",
    "            self.split_rule = split_rule # (feature, threshhold)\n",
    "    \n",
    "    def __init__(self, SMALLEST_OK_LEAF=1):\n",
    "        self.SMALLEST_OK_LEAF = SMALLEST_OK_LEAF\n",
    "        self.root = self.Node()\n",
    "        \n",
    "    def segmenter(self, data, labels, depth):\n",
    "        # A method that takes in data and labels. When called, it finds the best split rule\n",
    "        # for a Node using the impurity measure and input data.\n",
    "        \n",
    "        # stopping conditions\n",
    "        if len(labels) <= self.SMALLEST_OK_LEAF:\n",
    "            return None\n",
    "        \n",
    "        if (np.sum(labels) == 0 or np.sum(labels) == len(labels)):\n",
    "            return None\n",
    "        \n",
    "        num_features = len(data[0])\n",
    "        \n",
    "        # which feature to split on?\n",
    "        impurities = np.zeros(num_features)\n",
    "        for j in range(num_features):\n",
    "            # suppose split on j, quantify the split quality.\n",
    "            left_label_hist = [[0,0],[1,0]]\n",
    "            right_label_hist = [[0,0],[1,0]]\n",
    "                \n",
    "            left_label_hist[1][1] = np.sum(labels[np.where(data[:,j] == 0)]) # number of ones in left split\n",
    "            right_label_hist[1][1] = np.sum(labels[np.where(data[:,j] == 1)])\n",
    "            left_label_hist[0][1] = len(labels[np.where(data[:,j] == 0)]) - left_label_hist[1][1] # number of zeros (is the rest of left data)\n",
    "            right_label_hist[0][1] = len(labels[np.where(data[:,j] == 1)]) - right_label_hist[1][1]\n",
    "\n",
    "            impurities[j] = self.impurity(left_label_hist, right_label_hist)\n",
    "            if (np.isnan(impurities[j])):\n",
    "                print('ENCOUNTERED NAN')\n",
    "                print(left_label_hist, right_label_hist)\n",
    "                \n",
    "        if np.min(impurities) == 0:\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            return np.argmin(impurities) # best feature\n",
    "        \n",
    "    def train(self, tree, data, labels, depth=2):\n",
    "        # Grows a decision tree by constructing nodes.\n",
    "        \n",
    "        # A stopping condition (too deep or empty node)\n",
    "        if depth <= 0 or len(data)==0:\n",
    "            average = np.sum(labels)/len(labels)\n",
    "            if average >= 0.5:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            tree.label = label\n",
    "            return tree\n",
    "        \n",
    "        split_point = self.segmenter(data, labels, depth)\n",
    "        if split_point == None:\n",
    "            if int(np.rint(np.mean(labels))) >= 1:\n",
    "                tree.label = 1\n",
    "            else:\n",
    "                tree.label = 0\n",
    "        else:\n",
    "            left_inds = np.where(data[:,split_point] == 0)\n",
    "            right_inds = np.where(data[:,split_point] == 1)\n",
    "            left_data = data[left_inds]\n",
    "            right_data = data[right_inds]\n",
    "            left_labels = labels[left_inds]\n",
    "            right_labels = labels[right_inds]\n",
    "            tree.split_rule = (split_point, np.mean(data[:,split_point]))\n",
    "            tree.left = self.train(self.Node(), left_data, left_labels, depth-1)\n",
    "            tree.right = self.train(self.Node(), right_data, right_labels, depth-1)\n",
    "        return tree\n",
    "\n",
    "    def predict(self, data, show=False, i=5):\n",
    "        # Traverses the tree to find the best label to classify the data point.\n",
    "        cur_node = self.root\n",
    "        origi = i\n",
    "        if show:\n",
    "            wohs = []\n",
    "        while (cur_node.label == None and i):\n",
    "            split_point = cur_node.split_rule[0]\n",
    "            thresh = cur_node.split_rule[1]\n",
    "            if show:\n",
    "                wohs += [ (split_point, data[split_point], thresh) ]\n",
    "                print(origi-i+1, split_point, data[split_point], thresh)\n",
    "                i-=1\n",
    "            if (data[split_point] < thresh):\n",
    "                cur_node = cur_node.left\n",
    "            else:\n",
    "                cur_node = cur_node.right\n",
    "            if (cur_node.label>1):\n",
    "                print(cur_node.split_rule)\n",
    "                print(cur_node.label)\n",
    "        return int(cur_node.label)\n",
    "    \n",
    "    def predict_all(self, test_data):\n",
    "        predns = [0,0]\n",
    "        pred_labels = []\n",
    "        errors = 0\n",
    "        for i in range(len(test_data)):\n",
    "            sample = test_data[i]\n",
    "            predn = self.predict(sample)\n",
    "            if predn > 1:\n",
    "                print(predn)\n",
    "            predns[predn] += 1\n",
    "            pred_labels += [predn]\n",
    "        plt.stem(predns)\n",
    "        plt.xlim([-.2,1.2])\n",
    "        plt.title('Number of each class')\n",
    "#         print('Preidcted 1 : Total ratio =', predns[1]/len(test_data))\n",
    "        return np.array(pred_labels)\n",
    "    \n",
    "    def WSE(self, left_label_hist, right_label_hist):\n",
    "        return self.weighted_sum_of_entropy(left_label_hist, right_label_hist)\n",
    "    \n",
    "    def weighted_sum_of_entropy(self, left_label_hist, right_label_hist):\n",
    "        # we choose the split which MINimizes this quanitity\n",
    "        # for spam, two hists may be: ex. [( (0, 134), (1, 57)), ( (0, 12), (1, 19))]\n",
    "        # card_X -> cardinality of X histogram\n",
    "        card_left = left_label_hist[0][1] + left_label_hist[1][1]\n",
    "        card_right = right_label_hist[0][1] + right_label_hist[1][1]\n",
    "        return (card_left*self.entropy(left_label_hist) + card_right*self.entropy(right_label_hist))/(card_left+card_right+1e-11)\n",
    "    \n",
    "    def entropy(self, hist):\n",
    "        # of a node, often a proposed node.\n",
    "        # hist = (...,(feature_i, frequency),...)\n",
    "        total = hist[0][1] + hist[1][1] + 1e-15\n",
    "        prob0 = hist[0][1]/total\n",
    "        prob1 = hist[1][1]/total\n",
    "        return prob0*self.surprise(prob0) + prob1*self.surprise(prob1)\n",
    "        \n",
    "    def surprise(self, probability):\n",
    "        return -((np.log(probability + 1e-15))/np.log(2))\n",
    "\n",
    "    def impurity(self, left_label_hist, right_label_hist):\n",
    "    # A method that takes in the result of a split: two histograms (a histogram is a mapping\n",
    "    # from label values to their frequencies) that count the frequencies of labels on the ”left”\n",
    "    # and ”right” side of that split. The method calculates and outputs a scalar value\n",
    "    # representing the impurity (i.e. the ”badness”) of the specified split on the input data.\n",
    "    # for spam: ( (0, 134), (1, 57))\n",
    "        card_left = left_label_hist[0][1] + left_label_hist[1][1]\n",
    "        card_right = right_label_hist[0][1] + right_label_hist[1][1]\n",
    "        return ((card_left)*(gini_impurity(left_label_hist)) + (card_right)*(gini_impurity(right_label_hist)))/(card_left+card_right+1e-13)\n",
    "    \n",
    "def gini_impurity(hist):\n",
    "    # Y can be thought of as a vector of labels, where a label equals a class C in classes.\n",
    "    # we are only interested in the labels indexed by S. The other samples aren't being worked on.\n",
    "    sum_prob_squared = 0\n",
    "    card = hist[0][1] + hist[1][1]\n",
    "    sum_prob_squared = (hist[0][1]/(card+1e-13))**2 + (hist[1][1]/(card+1e-13))**2\n",
    "    return 1-sum_prob_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    # for two-class data with binary features vectorized samples.\n",
    "    class Node:\n",
    "        def __init__(self, left=None, right=None, label=None, split_rule=None):\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.label = label\n",
    "            self.split_rule = split_rule # (feature, threshhold)\n",
    "    \n",
    "    def __init__(self, SMALLEST_OK_LEAF=1, m=7):\n",
    "        # random subset features used at each split, size equals \"m\" in range [1,d].\n",
    "        self.m = m\n",
    "        self.SMALLEST_OK_LEAF = SMALLEST_OK_LEAF\n",
    "        self.root = self.Node()\n",
    "        \n",
    "    def segmenter(self, data, labels, depth):\n",
    "        # A method that takes in data and labels. When called, it finds the best split rule\n",
    "        # for a Node using the impurity measure and input data.\n",
    "        \n",
    "        # stopping conditions\n",
    "        if len(labels) <= self.SMALLEST_OK_LEAF:\n",
    "            return None\n",
    "        \n",
    "        if (np.sum(labels) == 0 or np.sum(labels) == len(labels)):\n",
    "            return None\n",
    "        \n",
    "        # Random Subspace Selection\n",
    "        features = np.random.permutation(len(data[0]))[:self.m]\n",
    "        \n",
    "        # which feature to split on?\n",
    "        impurities = np.zeros(len(features))\n",
    "        for imp_idx in range(len(features)):\n",
    "            j = features[imp_idx]\n",
    "            # suppose split on j, quantify the split quality.\n",
    "            left_label_hist = [[0,0],[1,0]]\n",
    "            right_label_hist = [[0,0],[1,0]]\n",
    "                \n",
    "            left_label_hist[1][1] = np.sum(labels[np.where(data[:,j] == 0)]) # number of ones in left split\n",
    "            right_label_hist[1][1] = np.sum(labels[np.where(data[:,j] == 1)])\n",
    "            left_label_hist[0][1] = len(labels[np.where(data[:,j] == 0)]) - left_label_hist[1][1] # number of zeros (is the rest of left data)\n",
    "            right_label_hist[0][1] = len(labels[np.where(data[:,j] == 1)]) - right_label_hist[1][1]\n",
    "            \n",
    "            impurities[imp_idx] = checknan = self.impurity(left_label_hist, right_label_hist)\n",
    "\n",
    "            if (np.isnan(checknan)):\n",
    "                print('ENCOUNTERED NAN')\n",
    "                print(left_label_hist, right_label_hist)\n",
    "                \n",
    "        if np.min(impurities) == 0:\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            return features[np.argmin(impurities)] # best feature is indexed in features!\n",
    "        \n",
    "    def train(self, tree, data, labels, depth=2):\n",
    "        # Grows a decision tree by constructing nodes.\n",
    "        \n",
    "        # A stopping condition (too deep or empty node)\n",
    "        if depth <= 0 or len(data)==0:\n",
    "            average = np.sum(labels)/len(labels)\n",
    "            if average >= 0.5:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            tree.label = label\n",
    "            return tree\n",
    "        \n",
    "        split_point = self.segmenter(data, labels, depth)\n",
    "        if split_point == None:\n",
    "            if int(np.rint(np.mean(labels))) >= 1:\n",
    "                tree.label = 1\n",
    "            else:\n",
    "                tree.label = 0\n",
    "        else:\n",
    "            left_inds = np.where(data[:,split_point] == 0)\n",
    "            right_inds = np.where(data[:,split_point] == 1)\n",
    "            left_data = data[left_inds]\n",
    "            right_data = data[right_inds]\n",
    "            left_labels = labels[left_inds]\n",
    "            right_labels = labels[right_inds]\n",
    "            tree.split_rule = (split_point, np.mean(data[:,split_point]))\n",
    "            tree.left = self.train(self.Node(), left_data, left_labels, depth-1)\n",
    "            tree.right = self.train(self.Node(), right_data, right_labels, depth-1)\n",
    "        return tree\n",
    "\n",
    "    def predict(self, data, show=False, i=5):\n",
    "        # Traverses the tree to find the best label to classify the data point.\n",
    "        cur_node = self.root\n",
    "        origi = i\n",
    "#         while (cur_node.label == None and i):\n",
    "#             split_point = cur_node.split_rule[0]\n",
    "#             thresh = cur_node.split_rule[1]\n",
    "#             if show:\n",
    "#                 print(origi-i+1, split_point, thresh)\n",
    "#                 i-=1\n",
    "#             if (data[split_point] < thresh):\n",
    "#                 cur_node = cur_node.left\n",
    "#             else:\n",
    "#                 cur_node = cur_node.right\n",
    "#             if (cur_node.label>1):\n",
    "#                 print(cur_node.split_rule)\n",
    "#                 print(cur_node.label)\n",
    "#         return int(cur_node.label)\n",
    "        if show:\n",
    "            wohs = []\n",
    "        while (cur_node.label == None and i):\n",
    "            split_point = cur_node.split_rule[0]\n",
    "            thresh = cur_node.split_rule[1]\n",
    "            if show:\n",
    "                wohs += [ (split_point, data[split_point], thresh) ]\n",
    "                print(origi-i+1, split_point, data[split_point], thresh)\n",
    "                i-=1\n",
    "            if (data[split_point] < thresh):\n",
    "                cur_node = cur_node.left\n",
    "            else:\n",
    "                cur_node = cur_node.right\n",
    "            if (cur_node.label>1):\n",
    "                print(cur_node.split_rule)\n",
    "                print(cur_node.label)\n",
    "        if show:\n",
    "            return wohs\n",
    "        return int(cur_node.label)\n",
    "    \n",
    "    def predict_all(self, test_data):\n",
    "        predns = [0,0]\n",
    "        pred_labels = []\n",
    "        errors = 0\n",
    "        for i in range(len(test_data)):\n",
    "            sample = test_data[i]\n",
    "            predn = self.predict(sample)\n",
    "            if predn > 1:\n",
    "                print(predn)\n",
    "            predns[predn] += 1\n",
    "            pred_labels += [predn]\n",
    "        plt.stem(predns)\n",
    "        plt.xlim([-.2,1.2])\n",
    "        plt.title('Number of each class')\n",
    "#         print('Preidcted 1 : Total ratio =', predns[1]/len(test_data))\n",
    "        return np.array(pred_labels)\n",
    "    \n",
    "    def WSE(self, left_label_hist, right_label_hist):\n",
    "        return self.weighted_sum_of_entropy(left_label_hist, right_label_hist)\n",
    "    \n",
    "    def weighted_sum_of_entropy(self, left_label_hist, right_label_hist):\n",
    "        # we choose the split which MINimizes this quanitity\n",
    "        # for spam, two hists may be: ex. [( (0, 134), (1, 57)), ( (0, 12), (1, 19))]\n",
    "        # card_X -> cardinality of X histogram\n",
    "        card_left = left_label_hist[0][1] + left_label_hist[1][1]\n",
    "        card_right = right_label_hist[0][1] + right_label_hist[1][1]\n",
    "        return (card_left*self.entropy(left_label_hist) + card_right*self.entropy(right_label_hist))/(card_left+card_right+1e-11)\n",
    "    \n",
    "    def entropy(self, hist):\n",
    "        # of a node, often a proposed node.\n",
    "        # hist = (...,(feature_i, frequency),...)\n",
    "        total = hist[0][1] + hist[1][1] + 1e-15\n",
    "        prob0 = hist[0][1]/total\n",
    "        prob1 = hist[1][1]/total\n",
    "        return prob0*self.surprise(prob0) + prob1*self.surprise(prob1)\n",
    "        \n",
    "    def surprise(self, probability):\n",
    "        return -((np.log(probability + 1e-15))/np.log(2))\n",
    "\n",
    "    def impurity(self, left_label_hist, right_label_hist):\n",
    "    # A method that takes in the result of a split: two histograms (a histogram is a mapping\n",
    "    # from label values to their frequencies) that count the frequencies of labels on the ”left”\n",
    "    # and ”right” side of that split. The method calculates and outputs a scalar value\n",
    "    # representing the impurity (i.e. the ”badness”) of the specified split on the input data.\n",
    "    # for spam: ( (0, 134), (1, 57))\n",
    "        card_left = left_label_hist[0][1] + left_label_hist[1][1]\n",
    "        card_right = right_label_hist[0][1] + right_label_hist[1][1]\n",
    "        return ((card_left)*(gini_impurity(left_label_hist)) + (card_right)*(gini_impurity(right_label_hist)))/(card_left+card_right+1e-13)\n",
    "    \n",
    "def gini_impurity(hist):\n",
    "    # Y can be thought of as a vector of labels, where a label equals a class C in classes.\n",
    "    # we are only interested in the labels indexed by S. The other samples aren't being worked on.\n",
    "    sum_prob_squared = 0\n",
    "    card = hist[0][1] + hist[1][1]\n",
    "    sum_prob_squared = (hist[0][1]/(card+1e-13))**2 + (hist[1][1]/(card+1e-13))**2\n",
    "    return 1-sum_prob_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_feats = np.array(['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = csv.reader(open('census_data/train_data.csv','r'))\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for row in reader:\n",
    "    train_data += [row[:-1]]\n",
    "    train_labels += [row[-1]] # label is in last feature ~ last column\n",
    "categories = np.array(train_data)[0] # first row\n",
    "train_data = np.array(train_data)[1:] # skip first row entry = categories\n",
    "train_labels = np.array(train_labels)[1:].astype(np.int) # skip first row entry = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Impute '?' in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['38.6681945972' 'Private' '189277.381891' 'HS-grad' '10.0763354113'\n",
      " 'Married-civ-spouse' 'Exec-managerial' 'Husband' 'White' 'Male'\n",
      " '1094.81634275' '86.9095465102' '40.4178584525' 'United-States']\n"
     ]
    }
   ],
   "source": [
    "mff = get_most_freq_feats(train_data, '?', categories, categorical_feats)\n",
    "impute_missing_value(train_data, mff, '?')\n",
    "print(mff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fnlwgt class has too many unique values,\n",
    "# so vectorizing isn't a good idea until I reduce it by centering and floor dividing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnlwgt_feat = 2\n",
    "train_data[:,fnlwgt_feat] = ((train_data[:,fnlwgt_feat].astype(np.float) - ((train_data[:,fnlwgt_feat].astype(np.float).min())))//5000).astype('S26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a list of dictionaries, each dictionary corresponds to a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dicts = [dict(zip(categories, row)) for row in train_data] # each sample is now a dict. labels and samples still in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize data, i.e, expand the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False) # want regular 'ol arrays.\n",
    "train_vectorized = dv.fit_transform(train_dicts)\n",
    "categories_vectorized = np.array(dv.feature_names_) # new labels because we expanded categorical features (vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['38.6681945972' 'Private' '189277.381891' 'HS-grad' '10.0763354113'\n",
      " 'Married-civ-spouse' 'Exec-managerial' 'Husband' 'White' 'Male'\n",
      " '1094.81634275' '86.9095465102' '40.4178584525' 'United-States']\n"
     ]
    }
   ],
   "source": [
    "reader = csv.reader(open('census_data/test_data.csv','r'))\n",
    "kaggle_data = []\n",
    "for row in reader:\n",
    "    kaggle_data += [row]\n",
    "kaggle_data = np.array(kaggle_data)[1:] # skip first row entry = categories\n",
    "\n",
    "print(mff)\n",
    "impute_missing_value(kaggle_data, mff, '?')\n",
    "\n",
    "fnlwgt_feat = 2\n",
    "kaggle_data[:,fnlwgt_feat] = ((kaggle_data[:,fnlwgt_feat].astype(np.float) - ((train_data[:,fnlwgt_feat].astype(np.float).min())))//5000).astype('S26')\n",
    "\n",
    "kaggle_dicts = [dict(zip(categories, row)) for row in kaggle_data] # each test sample is now a dict.\n",
    "\n",
    "kaggle_vectorized = dv.transform(kaggle_dicts) # don't fit to this! only transform it, because we want the labels on training and test to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a decision tree on census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt = 10\n",
    "train_inds, test_inds = generate_inds(train_vectorized, pt)\n",
    "XXX, prune_inds = generate_inds(train_vectorized, pt)\n",
    "\n",
    "training = train_vectorized[train_inds]\n",
    "training_labels = train_labels[train_inds]\n",
    "\n",
    "test = train_vectorized[test_inds]\n",
    "test_labels = train_labels[test_inds]\n",
    "\n",
    "pruneset = train_vectorized[prune_inds]\n",
    "prune_labels = train_labels[prune_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n"
     ]
    }
   ],
   "source": [
    "biggest_leaf_when_stop_okay = 7\n",
    "depth = 10\n",
    "\n",
    "dt = DecisionTree(biggest_leaf_when_stop_okay)\n",
    "dt.train(dt.root, training, training_labels, depth)\n",
    "print(countnodesandleaves(dt.root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 0.143948655257\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\non0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a5001d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predn_labels = dt.predict_all(test);\n",
    "print('Error', np.sum(predn_labels != test_labels)/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a random forest on census data.\n",
    "\n",
    "m = int(np.rint(0.666*(len(categories_vectorized))))\n",
    "print('m:', m)\n",
    "\n",
    "biggest_leaf_when_stop_okay = 2\n",
    "forest_depth = 10\n",
    "\n",
    "rf = RandomForest(biggest_leaf_when_stop_okay, m)\n",
    "rf.train(rf.root, training, training_labels, forest_depth)\n",
    "\n",
    "predn_labels = rf.predict_all(test);\n",
    "print('Error:', np.sum(predn_labels != test_labels)/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build T decision trees, average their result. Samples chosen by bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = train_vectorized[train_inds]\n",
    "training_labels = train_labels[train_inds]\n",
    "\n",
    "test = train_vectorized[test_inds]\n",
    "test_labels = train_labels[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = 10\n",
    "pt = 10\n",
    "treetype = 'DecisionTree'\n",
    "depth = 13\n",
    "m = 220\n",
    "size_to_stop = 1\n",
    "bagging = True\n",
    "prune = False\n",
    "\n",
    "trees = grow_set_trees(num_trees, pt, training, training_labels, treetype, depth, m, size_to_stop, bagging, prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Error of 20 trees:', 0.14058679706601468)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGHpJREFUeJzt3X2wXXV97/H3J4QTgaAxN21IQjRYgxIGDDIQH3DYtEpD\n20u4dspTxVgCxaYVxo69JnSunCtzK965ZaDXgd6JSEKt0bS0FDXERJpdHa+QoUMwElOINcIJSXgQ\nCFivSeR7/1i/Exbbc/bDedjr7Pw+r5k9/PZvPX33zlnrs9dvrb1RRGBmZvmZVHUBZmZWDQeAmVmm\nHABmZplyAJiZZcoBYGaWKQeAmVmmHAA2YUlaLenGCrd/p6SfSHqgi9t8RdJbJsp67MjmALC2Sdol\naZ+kY0t9V0naPE6bjPToOknvA94PzI6Id1VRg9l4cwBYpyYB13VxexqTlUid/q2/GdgVEf9vLLZv\nNhE5AKwTAfwv4BOS3tA4UdK8NPQwqdRXl7QstT8i6TuSbpb0vKSdkt4j6Q8kPZHOLj7csNoZkjZK\n2p/W9abSut8uaZOk5yTtkPR7pWmrJd0uab2kl4HaEPXOlnRvWv5xSVel/mXAKuDdkl6SdMNQb4ak\nKyVtT8NEGxpquzW9phclPSTpnNK0SZKuT69/f5o+p7TqD0h6LL1Hnxv6n6Kt9QzO99uSHk61PFF+\nPZJeJ+mLkp5N29si6VdL/14/TOv+d0mXD1eL9aiI8MOPth7Aj4DfAO4Gbkx9VwGbU3se8AowqbTM\nZuDK1P4IcBBYSvHJ/kZgAPjfwNHAB4D9wLFp/tXp+TlAH3AL8O007TjgybSuScBC4BnglNKyLwDv\nTs+nDPF6vgV8Lq37HcDTwHlp2tLBbQ3zXiwBHgfelrb/58B3StN/H3hjmvanwB6gL037M+B7wPz0\n/HRgemq/AtwLvB6Ym2r6zWFqaLWet6T2ucCpqX0asBdYkp5fk7b3uvRvcgZwfHp/XyyteyawoOq/\nQT/G9lF5AX70ziMFwK8Dp6aD64wRBMBjpWmnpfl/pdT3LHB6aq8GvlSadhxwCDgRuAT4VkN9/wf4\nVGnZ1U1ey9y0ruNKfX8B3FmqtVkA3Df4utLzScBPgbnDzP8T4LTU/jfgPw8z3yvAe0rPvwJ8cph5\nd7RYz1uGmXYLcHNq/wHwncHaGt7r54EPAsdU/bfnx/g8PARkHYuIR4GvASvo/CLtvlL7Z2l9zzT0\nTR3cFMUZwuB2f0pxIJ1NMUa/KA1bPC/peeByik+qg8s+2aSO2cBP0joHPQH80hDKMN4M3Fra9nOp\nfw6ApE+k4aEX0vQ3UAQmFAH2wybr3ltq/wevvh+N5rZYD6mWRZI2S3pa0gsUn/r/U5r8N8A3gC9L\n2i3ps5Imp/flEuCjwFOSvibpba22Zb3FAWAjdQNwNa89YA4eTI8t9Z0wim2I4iBXPJGmAtOB3RQH\n63+JiDeWHsdHxB+3ue6ngOlpnYPeRClwWngC+MOG7R8XEQ+kO4j+DPi9iJgWEW+kGE4ZvKD9JPDW\nNrfTTLvr+RJwD3BiREwD/pq070fEoYj4dEScCrwH+B3gw2naxog4n+LfcAfFdRE7gjgAbEQi4ocU\nwxPXlfqeoTg4XyHpKElXAr82yk39lqT3SuqjuGbw3YjYDXwdOFnShyQdnR5nSXp7Wq7p3UMR8STw\nf4HPSJoi6XTgSuCLbdb118D1khYASHpD6SL08RTDS89K6pP0KYox/UGfB26U9FYVTpc0fZjtNHsd\n7a5nKvB8RByQdDbFmVKkumuSTpN0FPASxTWaX0j6VUlLJB2X+n4K/KL122K9xAFgo/Fpik/75WGg\nqyk+/T4LLKAYXx401H39zYaQAvhbirON5yguUH4IICJeAs4HLqUInT3AZygu6A63rUaXUVy3eAr4\nB4rrB//czvIRcQ/wWYqhkxeBbcBvpskb0uMxYBfFsNYTpcVvBtYBGynODFZRXIQd3G7jezBcHe2u\nZznwaUn7gf9GEdyDTgD+Li2/HahTDAtNAj5O8d4+B7wP+KNh6rAepYjh9xFJrwP+BZhCsWP9U0Ss\nTJ8yvkK6Vxq4OCJeSMuspPgk9Qvg2ojYmPrPpLgw9zpgfUR0815yMzNr0PQMIIovwZwXEQspbjE7\nL93PvALYFBEnA/en56TT4UsoPvktBm6TNHgKezuwLCLmA/MlLR6PF2RmZu1pOQQUEf+Rmn3AURS3\nhl0IrEn9a4CLUnsJsDYiDkbELmAnxZ0as4DjI2JLmu+u0jJmZlaBlgGQvm24leL2vc3pFsCZETF4\nO98+Xr31bjavvYtigOIukcb+3bR/u52ZmY2Dya1miIhXgIUqvvr/DUnnNUwPSf4/y5uZ9ZiWATAo\nIl6U9HXgTGCfpBMiYm8a3nk6zbab0n3bFF94GUj9Jzb0727choPEzGxkIqLjH05sOgQkaYakaal9\nDMVvtTxM8dshS9NsSym+ZELqvzTd+3wSMB/YEhF7gf3pG4kCrigt0/gievZxww03VF6D66++jhzr\n7+Xaj4T6R6rVGcAsYI2KX3ecBPxNRNwv6WFgnYpfTdwFXJwO3tslraO4n/gQsDxerW45xW2gx1Dc\nBrphxFWbmdmoNQ2AiNgGvHOI/p9Q/M8yhlrmLyh+VKux/18pfvzLzMwmAH8TeAzVarWqSxgV11+t\nXq6/l2uH3q9/pJp+E7jbJMVEqsfMrBdIIsb6IrCZmR25HABmZplyAJiZZcoBYGaWKQeAmVmmHABm\nZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWqVb/\nT2Brw5QpCzlwYBYwFXiZvr49/PznW6suy8ysKQfAKBUH/7OAVYf7Dhy4milTFjoEzGxC8xDQKBWf\n/Fc19K5K/WZmE5cDYNSmdthvZjYxOABG7eUO+83MJgYHwCj19e0Brm7ovSr1m5lNXIqIqms4TFJM\npHra9epdQPcBF/guIDPrKklEhDpebiIdcHs1AAZJ0MPlm1mPGmkAeAjIzCxTDgAzs0w1DQBJcyVt\nlvSopO9Lujb190sakPRwelxQWmalpMcl7ZB0fqn/TEnb0rRbx+8lmZlZO5peA5B0AnBCRGyVNBX4\nV+Ai4GLgpYi4uWH+BcCXgLOAOcA3gfkREZK2AH8SEVskrQf+KiI2NCzvawBmZh0al2sAEbE3Iram\n9svADygO7ABDbWwJsDYiDkbELmAnsEjSLOD4iNiS5ruLIkjMzKwibV8DkDQPOAN4IHV9TNIjku6Q\nNC31zQYGSosNUARGY/9uXg0SMzOrQFsBkIZ//h64Lp0J3A6cBCwE9gB/OW4VmpnZuGj5a6CSjgbu\nBr4YEfcARMTTpemfB76anu4G5pYWP5Hik//u1C737x5qe/39/YfbtVqNWq3W+lWYmWWkXq9Tr9dH\nvZ5WF4EFrAGei4iPl/pnRcSe1P44cFZEXF66CHw2r14Efmu6CPwgcC2wBfg6vghsZjYmRnoRuNUZ\nwHuBDwHfk/Rw6rseuEzSQiCAHwHXAETEdknrgO3AIWB56Yi+HFgNHAOsbzz4m5lZd/mnIMaQzwDM\nrAr+KQgzM+uIA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMO\nADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uU\nA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8tU0wCQNFfSZkmPSvq+pGtT\n/3RJmyQ9JmmjpGmlZVZKelzSDknnl/rPlLQtTbt1/F6SmZm1o9UZwEHg4xFxKvAu4I8lnQKsADZF\nxMnA/ek5khYAlwALgMXAbZKU1nU7sCwi5gPzJS0e81djZmZtaxoAEbE3Iram9svAD4A5wIXAmjTb\nGuCi1F4CrI2IgxGxC9gJLJI0Czg+Irak+e4qLWNmZhVo+xqApHnAGcCDwMyI2Jcm7QNmpvZsYKC0\n2ABFYDT27079ZmZWkcntzCRpKnA3cF1EvPTqqA5EREiKsSqov7//cLtWq1Gr1cZq1WZmR4R6vU69\nXh/1ehTR/Ngt6Wjga8B9EXFL6tsB1CJibxre2RwRb5e0AiAibkrzbQBuAH6c5jkl9V8GnBsRH23Y\nVrSqZyKToIfLN7MeJYmIUOs5X6vVXUAC7gC2Dx78k3uBpam9FLin1H+ppD5JJwHzgS0RsRfYL2lR\nWucVpWXMzKwCTc8AJJ0DfAv4HjA440pgC7AOeBOwC7g4Il5Iy1wPXAkcohgy+kbqPxNYDRwDrI+I\na4fYns8AzMw6NNIzgJZDQN3kADAz69y4DAGZmdmRywFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYp\nB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJll\nygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZm\nmWoZAJK+IGmfpG2lvn5JA5IeTo8LStNWSnpc0g5J55f6z5S0LU27dexfipmZdaKdM4A7gcUNfQHc\nHBFnpMd9AJIWAJcAC9Iyt0lSWuZ2YFlEzAfmS2pcp5mZdVHLAIiIbwPPDzFJQ/QtAdZGxMGI2AXs\nBBZJmgUcHxFb0nx3AReNrGQzMxsLo7kG8DFJj0i6Q9K01DcbGCjNMwDMGaJ/d+o3M7OKTB7hcrcD\nn07tG4G/BJaNRUH9/f2H27VajVqtNharNTM7YtTrder1+qjXo4hoPZM0D/hqRJzWbJqkFQARcVOa\ntgG4AfgxsDkiTkn9lwHnRsRHG9YV7dQzUUnQw+WbWY+SREQMNSzf1IiGgNKY/qD/AgzeIXQvcKmk\nPkknAfOBLRGxF9gvaVG6KHwFcM9Itm1mZmOj5RCQpLXAucAMSU9SfKKvSVpIcTfQj4BrACJiu6R1\nwHbgELC89JF+ObAaOAZYHxEbxvi1mJlZB9oaAuoWDwGZmXWuq0NAZmbW+xwAZmaZcgCYmWXKAWBm\nlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCY\nmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwA\nZmaZcgCYmWXKAWBmlqmWASDpC5L2SdpW6psuaZOkxyRtlDStNG2lpMcl7ZB0fqn/TEnb0rRbx/6l\nmJlZJ9o5A7gTWNzQtwLYFBEnA/en50haAFwCLEjL3CZJaZnbgWURMR+YL6lxnWZm1kUtAyAivg08\n39B9IbAmtdcAF6X2EmBtRByMiF3ATmCRpFnA8RGxJc13V2kZMzOrwEivAcyMiH2pvQ+YmdqzgYHS\nfAPAnCH6d6d+MzOryOTRriAiQlKMRTEA/f39h9u1Wo1arTZWqzYzOyLU63Xq9fqo16OI1sduSfOA\nr0bEaen5DqAWEXvT8M7miHi7pBUAEXFTmm8DcAPw4zTPKan/MuDciPhow3ainXomKgl6uHwz61GS\niAi1nvO1RjoEdC+wNLWXAveU+i+V1CfpJGA+sCUi9gL7JS1KF4WvKC1jZmYVaDkEJGktcC4wQ9KT\nwKeAm4B1kpYBu4CLASJiu6R1wHbgELC89JF+ObAaOAZYHxEbxvalmJlZJ9oaAuoWDwGZmXWu20NA\nZmbW4xwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXK\nAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZpiZXXYCZ\nWVWmTFnIgQOzgKnAy/T17eHnP99adVld4wAwsywVB/+zgFWH+w4cuJopUxZmEwIeAjKzLBWf/Fc1\n9K5K/XlwAJhZpqZ22H/kcQCYWaZe7rD/yOMAMLMs9fXtAa5u6L0q9edBEVF1DYdJiolUT6ck6OHy\nzbLz6l1A9wEX9OxdQJKICHW83GgOuJJ2AfuBXwAHI+JsSdOBrwBvBnYBF0fEC2n+lcCVaf5rI2Jj\nw/ocAGbWdb2+7440AEY7BBRALSLOiIizU98KYFNEnAzcn54jaQFwCbAAWAzcJslDUGZmFRmLA3Bj\n6lwIrEntNcBFqb0EWBsRByNiF7ATOBszM6vEWJwBfFPSQ5IGr6bMjIh9qb0PmJnas4GB0rIDwJxR\nbt/MzEZotN8Efm9E7JH0K8AmSTvKEyMiJDUbWevhUTczs942qgCIiD3pv89I+keKIZ19kk6IiL2S\nZgFPp9l3A3NLi5+Y+l6jv7//cLtWq1Gr1UZTopnZEader1Ov10e9nhHfBSTpWOCoiHhJ0nHARuC/\nA+8HnouIz0paAUyLiBXpIvCXKEJiDvBN4K3l2358F5CZVaHX992R3gU0mjOAmcA/Shpcz99GxEZJ\nDwHrJC0j3QYKEBHbJa0DtgOHgOU9fbQ3M+tx/iLYGOr1TxFmuer1fbeq7wGYmVmPcgCYmWXKAWBm\nlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCY\nmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwA\nZmaZcgCYmWXKAWBmlikHgJlZproaAJIWS9oh6XFJn+zmts3M7LW6FgCSjgI+BywGFgCXSTqlW9vv\njnrVBYxKvV6vuoRRcf3V6eXaC/WqC6hEN88AzgZ2RsSuiDgIfBlY0sXtd0G96gJGpdd3YtdfnV6u\nvVCvuoBKdDMA5gBPlp4PpD4zM6tANwMgurgtMzNrQRHdOS5LehfQHxGL0/OVwCsR8dnSPA4JM7MR\niAh1ukw3A2Ay8G/AbwBPAVuAyyLiB10pwMzMXmNytzYUEYck/QnwDeAo4A4f/M3MqtO1MwAzM5tY\nKv0msKTpkjZJekzSRknThphnrqTNkh6V9H1J11ZRa0NNLb/QJumv0vRHJJ3R7RqbaVW/pN9PdX9P\n0ncknV5FnUNp98uEks6SdEjSB7tZXytt/u3UJD2c/t7rXS6xqTb+dmZI2iBpa6r/IxWUOSRJX5C0\nT9K2JvNM5P22af0j2m8jorIH8D+B/5ranwRuGmKeE4CFqT2V4jrCKRXWfBSwE5gHHA1sbawH+C1g\nfWovAh6o8n0eQf3vBt6Q2osnSv3t1F6a75+BrwG/W3XdHb7304BHgRPT8xlV191h/f3AZwZrB54D\nJldde6rnfcAZwLZhpk/Y/bbN+jveb6v+LaALgTWpvQa4qHGGiNgbEVtT+2XgB8DsrlX4y9r5Qtvh\n1xURDwLTJM3sbpnDall/RHw3Il5MTx8ETuxyjcNp98uEHwP+Hnimm8W1oZ36LwfujogBgIh4tss1\nNtNO/XuA16f264HnIuJQF2scVkR8G3i+ySwTeb9tWf9I9tuqA2BmROxL7X1A0zdb0jyKBHxwfMtq\nqp0vtA01z0Q5iHb6hbxlwPpxrah9LWuXNIfioHR76ppIF7naee/nA9PTsOdDkq7oWnWttVP/KuBU\nSU8BjwDXdam2sTCR99tOtbXfjvtdQJI2UQzjNPrz8pOIiGbfA5A0leJT3XXpTKAq7R5QGu/JnSgH\norbrkHQecCXw3vErpyPt1H4LsCL9PYlf/neoUjv1Hw28k+J26WOB70p6ICIeH9fK2tNO/dcDWyOi\nJunXgE2S3hERL41zbWNlou63betkvx33AIiIDww3LV3QOCEi9kqaBTw9zHxHA3cDX4yIe8ap1Hbt\nBuaWns+l+KTQbJ4TU99E0E79pAtIq4DFEdHstLmb2qn9TODLxbGfGcAFkg5GxL3dKbGpdup/Eng2\nIn4G/EzSt4B3ABMhANqp/z3A/wCIiB9K+hHwNuChrlQ4OhN5v21Lp/tt1UNA9wJLU3sp8EsH9/Qp\n7g5ge0Tc0sXahvMQMF/SPEl9wCUUr6PsXuDDcPgb0C+Uhrqq1rJ+SW8C/gH4UETsrKDG4bSsPSLe\nEhEnRcRJFGeMfzRBDv7Q3t/OPwHnSDpK0rEUFyO3d7nO4bRT/w7g/QBp/PxtwL93tcqRm8j7bUsj\n2m8rvqo9Hfgm8BiwEZiW+mcDX0/tc4BXKO44eDg9Fldc9wUUdyPtBFamvmuAa0rzfC5NfwR4Z5X1\ndlo/8HmKuzcG3+8tVdfcyXtfmvdO4INV1zyCv51PUNwJtA24tuqaO/zbmQF8Nf3dbwMur7rmUu1r\nKX6F4ADFmdaVPbbfNq1/JPutvwhmZpapqoeAzMysIg4AM7NMOQDMzDLlADAzy5QDwMwsUw4AM7NM\nOQDMzDLlADAzy9T/B8MV5lpMuH1QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a9f4e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_predn_trees_labels = avg_prediction(trees, test)\n",
    "print('Error of 10 trees:', np.sum(avg_predn_trees_labels != test_labels)/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pruned_trees = []\n",
    "count = 0\n",
    "for tree in trees:\n",
    "    \n",
    "    print('before', count, countnodesandleaves(tree.root))\n",
    "    \n",
    "    XXX, prune_inds = generate_inds(training, pt)\n",
    "    pruneset = training[prune_inds]\n",
    "    prune_labels = training_labels[prune_inds]\n",
    "    postprune(tree.root, tree, pruneset, prune_labels)\n",
    "    \n",
    "    print('after', count, countnodesandleaves(tree.root))\n",
    "\n",
    "    pruned_trees += [tree]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Error of 20 pruned trees:', 0.13722493887530562)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGnVJREFUeJzt3X+0VXWd//Hni58qYkhMKophhCUuTXMlZabHmeTi8E38\n9l0j6mSY5NhQwrfvar6BZtxyLJs14xJz6cwyU5zK4juOjoUi5HCGlpOynOUPkkghUUFBxR9gkwb6\n/v6xPxc3p3vvOfeey9n3sl+Ptc5in8/+9T6Hs/fr7M/e+1xFBGZmVj6Dii7AzMyK4QAwMyspB4CZ\nWUk5AMzMSsoBYGZWUg4AM7OScgBYvyXpFklXFLj+myW9LOmBFq7zbUnv6y/Lsb2bA8AaJmmDpC2S\n9su1fV7Sij20ykiPlpP0CeCTwNiI+GgRNZjtaQ4A66lBwNwWrk99shCpp5/19wIbIuKNvli/WX/k\nALCeCODvga9IelftSEnjU9fDoFxbVdKsNHyBpPslXS3pFUnrJJ0k6XOSnklHF5+tWewYScskbUvL\nOjy37A9KWi5pq6S1kv4iN+4WSTdIulvS60Clk3rHSrorzf+kpM+n9lnAjcDHJG2XtKCzN0PShZLW\npG6ipTW1LUyv6TVJD0k6OTdukKRL0+vflsYfmlv06ZKeSO/RdZ3/VzS0nI7ppkl6ONXyTP71SNpH\n0g8kvZTWt0rSe3L/X+vTsn8r6byuarEBKiL88KOhB/AU8GfA7cAVqe3zwIo0PB54GxiUm2cFcGEa\nvgDYAcwk+2Z/BbAR+C4wFDgd2Absl6a/JT0/GRgGXAP8Io0bATybljUIOA54ETgqN++rwMfS8+Gd\nvJ6VwHVp2R8CXgBOS+Nmdqyri/diOvAk8IG0/suA+3Pj/xI4MI37P8DzwLA07m+Ax4CJ6fmxwOg0\n/DZwF3AAMC7V1NZFDfWW8740fCpwdBo+BtgMTE/PL07r2yf9nxwPjEzv72u5ZR8ETCr6M+hH3z4K\nL8CPgfNIAfCnwNFp5zqmFwHwRG7cMWn6P8m1vQQcm4ZvAX6UGzcC2AkcBswAVtbU90/A13Pz3tLN\naxmXljUi1/Yt4OZcrd0FwD0drys9HwT8DhjXxfQvA8ek4d8An+piureBk3LPfwJ8tYtp19ZZzvu6\nGHcNcHUa/hxwf0dtNe/1K8CngX2L/uz5sWce7gKyHouIx4GfAfPo+UnaLbnh36flvVjTtn/HqsiO\nEDrW+zuyHelYsj76yanb4hVJrwDnkX1T7Zj32W7qGAu8nJbZ4Rngj7pQuvBeYGFu3VtT+6EAkr6S\nuodeTePfRRaYkAXY+m6WvTk3/N+8837UGldnOaRaJktaIekFSa+Sfet/dxr9z8C9wI8lbZL0HUlD\n0vsyA/gC8Jykn0n6QL112cDiALDeWgBcxO47zI6d6X65toObWIfIdnLZE2l/YDSwiWxn/R8RcWDu\nMTIivtjgsp8DRqdldjicXODU8QzwVzXrHxERD6QriP4G+IuIGBURB5J1p3Sc0H4WeH+D6+lOo8v5\nEXAncFhEjAL+kbTtR8TOiPhmRBwNnAT8D+CzadyyiJhC9n+4luy8iO1FHADWKxGxnqx7Ym6u7UWy\nnfP5kgZLuhCY0OSq/lzSxyUNIztn8MuI2AQsAY6U9BlJQ9PjI5I+mObr9uqhiHgW+E/g25KGSzoW\nuBD4QYN1/SNwqaRJAJLelTsJPZKse+klScMkfZ2sT7/D94ArJL1fmWMlje5iPd29jkaXsz/wSkT8\nQdKJZEdKkequSDpG0mBgO9k5mrckvUfSdEkjUtvvgLfqvy02kDgArBnfJPu2n+8Guojs2+9LwCSy\n/uUOnV3X310XUgA/JDva2Ep2gvIzABGxHZgCnEMWOs8D3yY7odvVumqdS3be4jngX8nOH/x7I/NH\nxJ3Ad8i6Tl4DVgNtafTS9HgC2EDWrfVMbvargcXAMrIjgxvJTsJ2rLf2PeiqjkaXMxv4pqRtwOVk\nwd3hYOD/pfnXAFWybqFBwJfJ3tutwCeAv+6iDhugFNH1NiJpH+A/gOFkG9a/RcT89C3jJ6RrpYGz\nI+LVNM98sm9SbwFzImJZaj+B7MTcPsDdEdHKa8nNzKxGt0cAkd0Ec1pEHEd2idlp6XrmecDyiDgS\nuC89Jx0OzyD75jcVuF5SxyHsDcCsiJgITJQ0dU+8IDMza0zdLqCI+O80OAwYTHZp2JnAotS+CDgr\nDU8HbouIHRGxAVhHdqXGIcDIiFiVprs1N4+ZmRWgbgCkuw0fIbt8b0W6BPCgiOi4nG8L71x6N5bd\nr6LYSHaVSG37Jhq/3M7MzPaAIfUmiIi3geOU3fp/r6TTasaHJP9leTOzAaZuAHSIiNckLQFOALZI\nOjgiNqfunRfSZJvIXbdNdsPLxtR+WE37ptp1OEjMzHonInr8w4nddgFJGiNpVBrel+y3Wh4m++2Q\nmWmymWQ3mZDaz0nXPh8BTARWRcRmYFu6I1HA+bl5al/EgH0sWLCg8Bpcf/F1lLH+gVz73lB/b9U7\nAjgEWKTs1x0HAf8cEfdJehhYrOxXEzcAZ6ed9xpJi8muJ94JzI53qptNdhnovmSXgS7tddVmZta0\nbgMgIlYDH+6k/WWyP5bR2TzfIvtRrdr2/yL78S8zM+sHfCdwH6pUKkWX0BTXX6yBXP9Arh0Gfv29\n1e2dwK0mKfpTPWZmA4Ekoq9PApuZ2d7LAWBmVlIN3wdgXVuyZCXXXruMN98cwvDhO5kzZwrTpp1S\ndFlmZt1yADRpyZKVzJ17L+vXX7mrbf36ywAcAmbWr7kLqEnXXrtst50/wPr1V/Ld7y4vqCIzs8b4\nCKBJb745BFhJ9jc5hpDd/zaFN94YXGhdZmb1OACatG3bRrK/qZ0/CriMbdu2dDGHmVn/4C6gpg1j\n950/wJVIw4soxsysYQ6AJh1wwHs6bR858k9aXImZWc84AJo0fPjOTtv32eetFldiZtYzDoAmzZkz\nhQkTLtutbcKES7nkktMLqsjMrDEOgCZNm3YKCxe20dZ2OQBtbZezcOFU3wNgZv2efwyuD0kwgMs3\nswHKPwZnZmY94vsA+sB733s6zzwzBBiJtJ3DD9/J00/7TmAz69/cBdSkbOc/Hrgx13oRhx++wSFg\nZi3R2y4gB0CTpDOAezoZcwYRnbWbmfUtnwMozP49bDcz6x8cAE17vYftZmb9gwOgaS8BF9W0fR7Y\nWkAtZmaNcwA0acGCzwG/AT6VWj4FPMGCBRcUVpOZWSN8GWiT2ttnA3DddSvZuhXe/e4RfOlLZ+xq\nNzPrr3wVUB/yncBmVgRfBWRmZj3iADAzKykHgJlZSXUbAJLGSVoh6XFJv5I0J7W3S9oo6eH0OCM3\nz3xJT0paK2lKrv0ESavTuIV77iWZmVkjuj0JLOlg4OCIeETS/sB/AWcBZwPbI+LqmuknAT8CPgIc\nCvwcmBgRIWkV8KWIWCXpbuDaiFhaM79PApuZ9dAeOQkcEZsj4pE0/Drwa7IdO0BnK5sO3BYROyJi\nA7AOmCzpEGBkRKxK091KFiRmZlaQhs8BSBoPHA88kJoukfSopJskjUptY4GNudk2kgVGbfsm3gkS\nMzMrQEMBkLp//gWYm44EbgCOAI4Dngf+YY9VaGZme0TdO4ElDQVuB34QEXcCRMQLufHfA36anm4C\nxuVmP4zsm/+mNJxv39TZ+trb23cNVyoVKpVK/VdhZlYi1WqVarXa9HLqnQQWsAjYGhFfzrUfEhHP\np+EvAx+JiPNyJ4FP5J2TwO9PJ4EfBOYAq4Al+CSwmVmf6O1J4HpHAB8HPgM8Junh1HYpcK6k44AA\nngIuBoiINZIWA2uAncDs3B59NnALsC9wd+3O38zMWsu/BdSHfARgZkXwbwGZmVmPOADMzErKAWBm\nVlIOADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQD\nwMyspBwAZmYl5QAwMyspB4CZWUk5AMzMSsoBYGZWUg4AM7OScgCYmZWUA8DMrKQcAGZmJeUAMDMr\nKQeAmVlJOQDMzErKAWBmVlIOADOzknIAmJmVVLcBIGmcpBWSHpf0K0lzUvtoScslPSFpmaRRuXnm\nS3pS0lpJU3LtJ0hancYt3HMvyczMGlHvCGAH8OWIOBr4KPBFSUcB84DlEXEkcF96jqRJwAxgEjAV\nuF6S0rJuAGZFxERgoqSpff5qzMysYd0GQERsjohH0vDrwK+BQ4EzgUVpskXAWWl4OnBbROyIiA3A\nOmCypEOAkRGxKk13a24eMzMrQMPnACSNB44HHgQOiogtadQW4KA0PBbYmJttI1lg1LZvSu1mZlaQ\nIY1MJGl/4HZgbkRsf6dXByIiJEVfFdTe3r5ruFKpUKlU+mrRZmZ7hWq1SrVabXo5iuh+3y1pKPAz\n4J6IuCa1rQUqEbE5de+siIgPSpoHEBFXpemWAguAp9M0R6X2c4FTI+ILNeuKevX0ZxIM4PLNbICS\nRESo/pS7q3cVkICbgDUdO//kLmBmGp4J3JlrP0fSMElHABOBVRGxGdgmaXJa5vm5eczMrADdHgFI\nOhlYCTwGdEw4H1gFLAYOBzYAZ0fEq2meS4ELgZ1kXUb3pvYTgFuAfYG7I2JOJ+vzEYCZWQ/19gig\nbhdQKzkAzMx6bo90AZmZ2d7LAWBmVlIOADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgJlZSTkA\nzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMyspB4CZWUk5AMzMSsoBYGZWUg4AM7OS\ncgCYmZWUA8DMrKQcAGZmJeUAMDMrKQeAmVlJOQDMzErKAWBmVlIOADOzknIAmJmVVN0AkPR9SVsk\nrc61tUvaKOnh9DgjN26+pCclrZU0Jdd+gqTVadzCvn8pZmbWE40cAdwMTK1pC+DqiDg+Pe4BkDQJ\nmAFMSvNcL0lpnhuAWRExEZgoqXaZZmbWQnUDICJ+AbzSySh10jYduC0idkTEBmAdMFnSIcDIiFiV\nprsVOKt3JZuZWV9o5hzAJZIelXSTpFGpbSywMTfNRuDQTto3pXYzMyvIkF7OdwPwzTR8BfAPwKy+\nKKi9vX3XcKVSoVKp9MVizcz2GtVqlWq12vRyFBH1J5LGAz+NiGO6GydpHkBEXJXGLQUWAE8DKyLi\nqNR+LnBqRHyhZlnRSD39lQQDuHwzG6AkERGddct3q1ddQKlPv8P/BDquELoLOEfSMElHABOBVRGx\nGdgmaXI6KXw+cGdv1m1mZn2jbheQpNuAU4Exkp4l+0ZfkXQc2dVATwEXA0TEGkmLgTXATmB27iv9\nbOAWYF/g7ohY2sevxczMeqChLqBWcReQmVnPtbQLyMzMBj4HgJlZSTkAzMxKygFgZlZSDgAzs5Jy\nAJiZlZQDwMyspBwAZmYl5QAwMyspB4CZWUk5AMzMSsoBYGZWUg4AM7OScgCYmZWUA8DMrKQcAGZm\nJeUAMDMrKQeAmVlJOQDMzErKAWBmVlIOADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgJlZSTkA\nzMxKygFgZlZSdQNA0vclbZG0Otc2WtJySU9IWiZpVG7cfElPSloraUqu/QRJq9O4hX3/UszMrCca\nOQK4GZha0zYPWB4RRwL3pedImgTMACalea6XpDTPDcCsiJgITJRUu0wzM2uhugEQEb8AXqlpPhNY\nlIYXAWel4enAbRGxIyI2AOuAyZIOAUZGxKo03a25eczMrAC9PQdwUERsScNbgIPS8FhgY266jcCh\nnbRvSu1mZlaQIc0uICJCUvRFMQDt7e27hiuVCpVKpa8WbWa2V6hWq1Sr1aaXo4j6+25J44GfRsQx\n6flaoBIRm1P3zoqI+KCkeQARcVWabimwAHg6TXNUaj8XODUivlCznmiknv5KggFcvpkNUJKICNWf\ncne97QK6C5iZhmcCd+baz5E0TNIRwERgVURsBrZJmpxOCp+fm8fMzApQtwtI0m3AqcAYSc8CXweu\nAhZLmgVsAM4GiIg1khYDa4CdwOzcV/rZwC3AvsDdEbG0b1+KmZn1RENdQK3iLiAzs55rdReQmZkN\ncA4AM7OScgCYmZWUA8DMrKQcAGZmJeUAMDMrKQeAmVlJOQDMzErKAWBmVlIOADOzknIAmJmVlAPA\nzKykHABmZiXlADAzKykHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMysp\nB4CZlVZ7+/WMGTODUaMuYMyYGbS3X190SS01pOgCzMyK0N5+Pd/4xp3AgbvasufQ3j67oKpaSxFR\ndA27SIr+VE9PSTCAyzcrlUGDTiLiaODGXOtFSGt4++37iyqrVyQREerpfO4CMrNSihjJ7jt/gBuJ\n2L+IcgrhADCzkhrRRbsDwMxsL/dmF+1vtLSKIjUVAJI2SHpM0sOSVqW20ZKWS3pC0jJJo3LTz5f0\npKS1kqY0W7yZWW/tt9+bwGU1rZcyYsQfiiinEM0eAQRQiYjjI+LE1DYPWB4RRwL3pedImgTMACYB\nU4HrJfkIxMwKsXjx1xk6dC1weWq5nKFD1/KTn1ze3Wx7lb7YAdeeeT4TWJSGFwFnpeHpwG0RsSMi\nNgDrgBMxMyvAtGmncMcdc2lry563tcEdd/xvpk07pdjCWqipy0Al/RZ4DXgL+KeIuFHSKxFxYBov\n4OWIOFDSd4EHIuKHadz3gHsi4vbc8nwZqJm13EDfdou6DPTjEXE8cAbwRUmfyI9Me/Pu3tYB/Jab\n2UC3ZMlK2tq+BkBb29dYsmRlwRW1VlN3AkfE8+nfFyXdQdals0XSwRGxWdIhwAtp8k3AuNzsh6W2\n3bS3t+8arlQqVCqVZko0M+vUkiUrmTv3XtavvxKAZcv+lvXrs5PC/b0bqFqtUq1Wm15Or7uAJO0H\nDI6I7ZJGAMuAbwCfBLZGxHckzQNGRcS8dBL4R2QhcSjwc+D9+T4fdwGZWau0tX2NZcv+tpP2y1m6\n9IoCKuq93nYBNXMEcBBwR9bNzxDghxGxTNJDwGJJs4ANwNkAEbFG0mJgDbATmD2g9/ZmNqC9+Wbn\nu7833hjc4kqK0+sAiIingOM6aX+Z7Cigs3m+BXyrt+s0M+sr27a90Gn79u0vtriS4vg6fDMrqT/Q\n2Y1gEV3dIbz3cQCYWSkdcMBhQBv5G8FgamovB/89ADMrpeHDdwKnpAdAduJ3n32WF1VSy/kIwMxK\nac6cKUyYsHsX0IQJl3LJJacXVFHrOQDMrJSmTTuFhQvbaGvLuoDa2i5n4cKp/f4egL7kvwjWh3wf\ngNnANNC3Xf9FMDMz6xEHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMysp\nB4CZWUk5AMzMSsoBYGZWUg4AM7OScgCYmZWUA8DMrKQcAGZmJeUAMDMrKQeAmVlJOQDMzErKAWBm\nVlIOADOzknIAmJmVVEsDQNJUSWslPSnpq61ct5mZ7a5lASBpMHAdMBWYBJwr6ahWrb81qkUX0JRq\ntVp0CU1x/cUZyLVnqkUXUIhWHgGcCKyLiA0RsQP4MTC9hetvgWrRBTRloG/Err84A7n2TLXoAgrR\nygA4FHg293xjajMzswK0MgCihesyM7M6FNGa/bKkjwLtETE1PZ8PvB0R38lN45AwM+uFiFBP52ll\nAAwBfgP8GfAcsAo4NyJ+3ZICzMxsN0NataKI2CnpS8C9wGDgJu/8zcyK07IjADMz618KvRNY0mhJ\nyyU9IWmZpFGdTDNO0gpJj0v6laQ5RdRaU1PdG9okXZvGPyrp+FbX2J169Uv6y1T3Y5Lul3RsEXV2\nptGbCSV9RNJOSZ9uZX31NPjZqUh6OH3eqy0usVsNfHbGSFoq6ZFU/wUFlNkpSd+XtEXS6m6m6c/b\nbbf192q7jYjCHsDfAf83DX8VuKqTaQ4GjkvD+5OdRziqwJoHA+uA8cBQ4JHaeoA/B+5Ow5OBB4p8\nn3tR/8eAd6Xhqf2l/kZqz03378DPgP9VdN09fO9HAY8Dh6XnY4quu4f1twPf7qgd2AoMKbr2VM8n\ngOOB1V2M77fbbYP193i7Lfq3gM4EFqXhRcBZtRNExOaIeCQNvw78Ghjbsgr/WCM3tO16XRHxIDBK\n0kGtLbNLdeuPiF9GxGvp6YPAYS2usSuN3kx4CfAvwIutLK4BjdR/HnB7RGwEiIiXWlxjdxqp/3ng\ngDR8ALA1Ina2sMYuRcQvgFe6maQ/b7d16+/Ndlt0ABwUEVvS8Bag2zdb0niyBHxwz5bVrUZuaOts\nmv6yE+3pDXmzgLv3aEWNq1u7pEPJdko3pKb+dJKrkfd+IjA6dXs+JOn8llVXXyP13wgcLek54FFg\nbotq6wv9ebvtqYa22z1+FZCk5WTdOLUuyz+JiOjuPgBJ+5N9q5ubjgSK0ugOpfaa3P6yI2q4Dkmn\nARcCH99z5fRII7VfA8xLnyfxx/8PRWqk/qHAh8kul94P+KWkByLiyT1aWWMaqf9S4JGIqEiaACyX\n9KGI2L6Ha+sr/XW7bVhPtts9HgARcXpX49IJjYMjYrOkQ4AXuphuKHA78IOIuHMPldqoTcC43PNx\nZN8UupvmsNTWHzRSP+kE0o3A1Ijo7rC5lRqp/QTgx9m+nzHAGZJ2RMRdrSmxW43U/yzwUkT8Hvi9\npJXAh4D+EACN1H8ScCVARKyX9BTwAeChllTYnP683Takp9tt0V1AdwEz0/BM4I927ulb3E3Amoi4\npoW1deUhYKKk8ZKGATPIXkfeXcBnYdcd0K/murqKVrd+SYcD/wp8JiLWFVBjV+rWHhHvi4gjIuII\nsiPGv+4nO39o7LPzb8DJkgZL2o/sZOSaFtfZlUbqXwt8EiD1n38A+G1Lq+y9/rzd1tWr7bbgs9qj\ngZ8DTwDLgFGpfSywJA2fDLxNdsXBw+kxteC6zyC7GmkdMD+1XQxcnJvmujT+UeDDRdbb0/qB75Fd\nvdHxfq8quuaevPe5aW8GPl10zb347HyF7Eqg1cCcomvu4WdnDPDT9LlfDZxXdM252m8j+xWCP5Ad\naV04wLbbbuvvzXbrG8HMzEqq6C4gMzMriAPAzKykHABmZiXlADAzKykHgJlZSTkAzMxKygFgZlZS\nDgAzs5L6/zkTgOvDOjc9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a0d1690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_predn_pruned_trees_labels = avg_prediction(pruned_trees, test)\n",
    "print('Error of 10 pruned trees:', np.sum(avg_predn_pruned_trees_labels != test_labels)/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = 10\n",
    "pt = 10\n",
    "treetype = 'RandomForest'\n",
    "depth = 400\n",
    "m = 36\n",
    "size_to_stop = 1\n",
    "bagging = True\n",
    "prune = False\n",
    "\n",
    "random_forests = grow_set_trees(num_trees, pt, train_vectorized, train_labels, treetype, depth, m, size_to_stop, bagging, prune)\n",
    "\n",
    "avg_predn_forests_labels = avg_prediction(random_forests, test)\n",
    "print('Error of 10 random forests:', np.sum(avg_predn_forests_labels != test_labels)/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.081461719816354389"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng5mZFTgYzMys4P8DRuD7lH9ygzYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b1fe0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kaggle_pdn_labels = np.array(avg_prediction(random_forests, kaggle_vectorized))[0]\n",
    "np.sum(kaggle_pdn_labels)/len(kaggle_pdn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_labels(kaggle_pdn_labels, 'cenus_labels_400depth10trees.csv')\n",
    "# Kaggle Score: 0.75533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KFold CV on depths for Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1189dad50>"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njXLI6W4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a3e1e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(depths[:12], depth_errors[:12])\n",
    "plt.title('Result of K-fold CV for Depth of Tree')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Average Error')\n",
    "# min at 13 when size_to_stop = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### sw\n",
    "# ms = [220]\n",
    "# kfold(5,'size_to_stop',training,training_labels,[1],'DecisionTree',depth=13,size_to_stop=None)\n",
    "# kfold(5,'depth',training,training_labels,depths,'DecisionTree',size_to_stop=7)\n",
    "# kfold(5,'m',training,training_labels,ms,'RandomForest',depth=13,size_to_stop=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
